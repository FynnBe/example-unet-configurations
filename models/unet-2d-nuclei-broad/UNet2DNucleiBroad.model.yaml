name: UNet2DNucleiBroad
description: A 2d U-Net pretrained on broad nucleus dataset.
cite:
    - text: "Ronneberger, Olaf et al. U-net: Convolutional networks for biomedical image segmentation. MICCAI 2015."
      doi: https://doi.org/10.1007/978-3-319-24574-4_28
authors:
    - Constantin Pape;@constantinpape
documentation: ../unet2d.md
tags: [unet2d, pytorch, nucleus-segmentation]

format_version: 0.1.0
language: python
framework: pytorch

source: torch_resource.models.unet.UNet2d
kwargs: {input_channels: 1, output_channels: 1}

test_input: ../test_input.npy
test_output: ../test_output.npy
thumbnail: ./nuclei_thumbnail.png

# TODO double check inputs/outputs
inputs:
  - name: input
    axes: bcyx
    data_type: float32
    data_range: [-inf, inf]
    shape:
        min: [1, 1, 32, 32]
        step: [null, 0, 32, 32]
outputs:
  - name: output
    axes: bcyx
    data_type: float32
    data_range: [0, 1]
    shape:
        reference_input: input
        scale: [1, 1, 1, 1]
        offset: [0, 0, 0, 0]
        halo: [0, 0, 32, 32]

prediction:
    preprocess:
        - spec: https://github.com/constantinpape/pytorch-resoure-stub:configurations/transformations/NormalizeZeroMeanUnitVariance.transformation.yaml:9fec4dd
          kwargs:
              eps: 1.0e-6  # currently all kwargs need to be specified (here or in the consumer)
              apply_to: [0]
    weights:
        source: TODO
        hash: {md5: TODO}
    postprocess: null
    dependencies: conda:../environment.yaml

training:
    setup:
        reader:
            spec: https://github.com/constantinpape/pytorch-resoure-stub:configurations/readers/BroadNucleusData.reader.yaml:9fec4dd
        sampler:
            spec: https://github.com/constantinpape/pytorch-resoure-stub:configurations/samplers/GrayscaleImageSampler.sampler.yaml:9fec4dd
        preprocess:
            - spec: https://github.com/constantinpape/pytorch-resoure-stub:configurations/transformations/NormalizeZeroMeanUnitVariance.transformation.yaml:9fec4dd
              kwargs: {eps: 1.0e-6, apply_to: [0]}
        loss:
            - spec: https://github.com/constantinpape/pytorch-resoure-stub:configurations/transformations/Sigmoid.transformation.yaml:9fec4dd
              kwargs: {apply_to: [0]}
            - spec: https://github.com/constantinpape/pytorch-resoure-stub:configurations/transformations/BCELoss.transformation.yaml:9fec4dd
        optimizer:
            source: torch.optim.Adam
            kwargs: {lr: 0.002}
        # validation:
        #   - {}
    source: ./train.py:train_unet2d_nuclei_broad
    kwargs: {n_epochs: 100}
    # enable different ways of specifying the dependencies.
    # this would hold all training dependencies, e.g. as a frozen conda environment
    # or as a pom.xml
    dependencies: # this is a file to the dependencies
        conda:../environment.yaml
    description: "Train the unet via binary cross entropy"
